\chapter{Аналитичекский раздел}

\section{Предметная область}

В настояще время все больше внимания привлекает тема автоматизации судоходства, а так же общее повышение уровня безопасмности в процессе эксплуатации судов.

Методы распознавания различных надводных объектов имеют особое значение в данном контексте, так как позволяют решить множество проблем: избежание столкновений судов, осуществление автономного плавания и пр.~\cite{ship-detection}.

Не менее важной является задача распознавания малых надводных объектов, поскольку традиционные методы обнаружения, основанные на использовании радара, не подходят для задачи обнаружения близко расположенных и малых объектов~\cite{small-ship-detection}.

Кроме того, обнаружение активности рыболовецких судов по-прежнему является сложной задачей для многих стран, расположенных на архипелагах, например --- Индонезии. В настоящее время для мониторинга огромной морской акватории используется технология, использующая датчики SAR для обнаружения кораблей, разрабатываемая с 1985 года. Однако стоимость использования данной технологии является одним из основных препятствий для дальнейшего развития~\cite{boats-recognition}.

\section{Нейронные сети}

ANN определяется как массово параллельный распределенный процессор, состоящий из простых процессорных блоков, который обладает естественной склонностью накапливать эмпирические знания~\cite{ann}. 

Их название и структура вдохновлены человеческим мозгом, а алгоритм работы основывается на способе, которым биологические нейроны передают сигналы друг другу.

В общем случае ANN включает в себя входной слой, выходной (или целевой) слой и, между ними, скрытый слой. Слои соединены через узлы (искусственные нейроны). Эти соединения образуют <<сеть>> --- нейронную сеть --- из взаимосвязанных узлов. Пример приведен на рисунке~\ref{img:network}.

\includeimage{network}{f}{h}{0.7\textwidth}{Пример схемы ANN}

В общем случае искусственный нейрон можно представить в виде регрессионной модели \cite{activationfuncs}, состоящей из входных данных, весовых коэффициентов, смещения (или порогового значения) и выходных данных. Эту модель можно описать следующей формулой:

\begin{equation}
	\label{eq:nn0}
	\hat{y} = \sum_{i=1}^{n}w_ix_i + w_0,
\end{equation}

В качестве функции активации можно использовать: ступенчатую, линейную функции, сигмоиду, ReLu и другие~\cite{activationfuncs}.

Модель искусственного нейрона приведенна на рисунке~\ref{img:neuron}.

\includeimage{neuron}{f}{h}{0.7\textwidth}{Общая схема искусственного нейрона}

Данное представление применимо к любому виду нейронных сетей --- вне зависимости от типа, нейронные сети реализуются путем упорядочивания нейронов в слои и последующим связыванием соответствующих слоев между собой~\cite{ann}.

В процессе обучения нейронной сети используется так называемая обучающая выборка --- заранее подготовленный набор данных, отражающий суть рассматриваемой предметной области~\cite{ann}. В зависимости от содержимого обучающей выборки результирующие весовые конфигурации нейронной сети (т.~е. веса связей между нейронами, а так же смещения отдельно взятых нейронов) могут отличаться~\cite{ann}. В связи с этим одна и та же структура нейронной сети может переиспользована для работы в различных предметных областях.

\section{Сверточные нейронные сети}

Одним из основных видов нейронных сетей, применяемых для распознавания является CNN~\cite{cnn}.

CNN представляет собой тип ANN, которая имеет архитектуру с глубокой обратной связью и выделяется на фоне остальных ANN с полносвязными слоями своей способностью к обобщению. CNN работает с сильно абстрагированными характеристиками объектов, особенно это касается пространственных данных, что позволяет добиться более эффективно идентифицировать объекты в сравнении с другими типами ANN~\cite{cnn}. Одним из отличительных свойств CNN является способность к фильтрации посторонних шумов во входных данных.

Модель CNN состоит из конечного набора уровней обработки, которые могут изучать различные характеристики входных данных (например, изображения) с несколькими уровнями абстракции. Начальные уровни изучают и извлекают высокоуровневые свойства, а более глубокие уровни изучают и извлекают более низкоуровневые свойства. Концептуальная модель CNN представлена на рисунке~\ref{img:cnn-conceptual-model}.

\includeimage{cnn-conceptual-model}{f}{h}{0.7\textwidth}{Концептуальная модель CNN}

Существующие архитектуры CNN для обнаружения объектов на изображениях можно разделить на две категории: одноэтапные (one-stage) и двухэтапные (two-stage)~\cite{review-on-one-stage-object-detection}.    

\subsection{Свертка}

\subsubsection*{Ядро}

Прежде, чем рассматривать процесс свертки, необходимо определить понятие <<ядро>>, используемое при свертке. Ядро предстваляет собой матрицу из дискретных значений или чисел, где каждое значение известно как вес этого ядра. Пример двухмерного ядра приведен на рисунке~\ref{img:convolution-kernel}.

\includeimage{convolution-kernel}{f}{h}{0.15\textwidth}{Пример двумерного ядра с размерностью $2 \times 2$}

Ядро инициализируется случайными значениями, которые изменяются в ходе обучения CNN.

\subsubsection*{Процесс свертки}

Свертка --- это операция над парой матриц $A(n_x, n_y)$ и $B(m_x, m_y)$, $m_x  \le n_x$, $m_y \le n_y$, результатом которой является матрица 

\begin{equation}
C(n_x - m_x +1, n_y - m_y + 1) = A * B,
\end{equation}

каждый элемент которой является скалдарным произведением матрицы $B$ (ядра свертки) и некоторой подматрицы $A$ такого же размера.

Т.~е. элемент матрицы C вычисляется следующим образом:
\begin{equation}
C_{i,j} = \Sigma_{u=0}^{m_x-1} \Sigma_{v=0}^{m_y-1} A_{i+u,j+v}B_{u,v}.
\end{equation}

\subsubsection*{Пример}

Разберем пример свертки для изображения в градациях серого, т.к. такое изображение содержит лишь один канал, передаваемый на вход CNN.

Пусть дано изображение, представленное на рисунке~\ref{img:convolution-input-example}.

\includeimage{convolution-input-example}{f}{h}{0.25\textwidth}{Пример изображения в градациях серого с размерностью $4 \times 4$}

Далее рассмотрим первые два шага процесса свертки, представленные на рисурках~\ref{img:convolution-example-1}~и~\ref{img:convolution-example-2}, соответсвенно.

\includeimage{convolution-example-1}{f}{h}{0.7\textwidth}{Пример свертки изображения в градациях серого с размерностью $4 \times 4$}

\includeimage{convolution-example-2}{f}{h}{0.75\textwidth}{Пример свертки изображения в градациях серого с размерностью $4 \times 4$}

Аналогичным образом свертка продолжается до полного заполнения результирующей матрицы. Стоит отметить, что, в зависимости от размеров окна и перекрытия окон, будет меняться размер результирующей матрицы.

\subsection{Двухэтапные CNN}

В таких нейросетевых алгоритмах выделяют два этапа: поиска RoI (англ. Candidate Region Extraction) на изобаржении и последующей классификации RoI, найденных на первом этапе. При этом под RoI на изображении подразумеваются зоны, потенциально содержащие искомые объекты~\cite{overview-of-two-stage-object-detection}. 

\includeimage{two-step-cnn}{f}{h}{0.8\textwidth}{Схема работы двухэтапного алгоритма}

Стоит отметить, что первый этап может происходить без использования нейронных сетей. Для этого можно использовать информациию о контрасте, ключевые точки или перебор всех возможных положений объекта с помощью процедуры~\texttt{selective search}~\cite{realtime-recognition-algorythm}.

RoI, полученные вышеперечисленными методами, могут обладать серьезными недостатками, например:
\begin{itemize}[label=---]
    \item содержать слишком большое количество фона;
    \item содержать лишь небольшую часть объекта;
    \item содержать более одного объекта.
\end{itemize}

В связи с этим на первом этапе более предпочтительным методом является применение CNN, не содержащих полносвязных слоев~\cite{realtime-recognition-algorythm}.

На втором этапе CNN применяеются к обнаруженным RoI.

Преимуществом данных алгоритмов является высокая точность распознавания объектов, однако, платой за это является время, необходисмое для выделения <<подозрительных>> зон на изображении~\cite{overview-of-two-stage-object-detection}.

\subsection{Одноэтапные CNN}

Данные нейросетевые алгоритмы не включают в себя этап поиска RoI на изображении.

\includeimage{one-step-cnn}{f}{h}{0.8\textwidth}{Схема работы одноэтапного алгоритма}

Преимуществами одноэтапных алгоритмов являются их простота и относительно высокая скорость работы. К недостаткам же можно отнести более низкую точность детектирования объектов по сравнению с двухэтапными алгоритмами, а также меньшую гибкость алгоритма с точки зрения рассматриваемых изображений~\cite{review-on-one-stage-object-detection}.

В настоящее время в CNN принято выделять несколько частей, использующихся в процессе работы. Общий вид современного одноэтапного детектора представлен на рисунке~\ref{img:modern-one-stage-detector}.

\includeimage{modern-one-stage-detector}{f}{h}{\textwidth}{Общий вид современного одноэтапного детектора}

Основными частями такой CNN являются:
\begin{itemize}[label=---]
    \item Backbone;
    \item Neck;
    \item Dense Prediction.
\end{itemize}

\section{Ансамбли}

Ансамбль --- это набор слабых экспертов, выполняющих классификацию произвольного объекта $x \in X$, конечный результат которого рассчитывается на основе результатов работы составляющих слабых экспертов. Слабыми эксператми в ансамбле могут выступать как классификаторы, так и другие ансамбли.

Тем не менее, ансамбль на основе нескольких моделей, построенных независимо друг от друга, в общем случае будет иметь более низкое качество, чем ансамбль на основе моделей, построенных с использованием специальных алгоритмов~\cite{ensembles}.

К этим алгоритмам относятся стекинг, бустинг и бэггинг, позволяющие существенно повысить качество классификации~\cite{ensembles}.

\subsection{Стекинг}

Стекинг подразумевает параллельные обучение и работу всеч слабых экспертов, т.~е. классификаторы не зависят друг от друга~\cite{ensembles}. 

Схема стекинга представлена на рис.~\ref{img:stacking}.

\includeimage{stacking}{f}{h}{\textwidth}{Схематическое представление алгоритма стекинга}

Обучающая выборка $X$ разделяется на $n$ случайных равновеликих частей (фолдов).

Для объекта из выборки, находяегося в $k$-ом фолде, производится предсказание слабыми экспертами, обучеными на $k-1$ фолдах. Данный процесс итеративен и происходит для каждого фолда.

Таким обрахом, для каждого объекта обучающей выборки создается набор прогнозов слабых экспертов. Далее, на сформированных наборах прогнозов происходит обучение метамодели~\cite{ensembles}.

\subsection{Бустинг}

При использовании бустинга, каждый последующий алгоритм, входящий в ансамбль, стремится компенсировать недостатки композиции всех предыдущих алгоритмов~\cite{ensembles}.

\subsubsection*{Формальная постановка задачи}

Пусть $h(a, \overrightarrow{x})$ --- слаюый эксперт, где $\overrightarrow{x}$ --- это вектор параметров. Необходимо найти следующий алгоритм:

\begin{equation}
H_T(a) = \Sigma_{t=1}^T b_th(a, \overrightarrow{x}),
\end{equation}

где $b_i \in \mathbb{R}$ --- коэффициенты, при которых

\begin{equation}
Q = \Sigma_iL(H_T(a_i), y_i) \to min,
\end{equation}

где $L$ --- функция потерь. 

Так как в общем случае процесс вычисления $\{(\overrightarrow{x}_t, b_t)\}_{t=1}^T$ нетривиален, решение находят пошагово:

\begin{equation}
H_t(a) = H_{t-1}(a) + b_th(a, \overrightarrow{x}).
\end{equation}

Схема бустинга представлена на рис.~\ref{img:boosting}.

\includeimage{boosting}{f}{h}{\textwidth}{Схематическое представление алгоритма бустинга}

\subsubsection*{Алгоритмы}

Среди наиболле часто используемых алгоритмов бустинга: AdaBoost и BrownBoost~\cite{ensembles}.

\subsection{Бэггинг}

В бэггинге все слабые эксперты обучаются и работают параллельно, т.~е. независимо друг от друга. При этом обучающая выборка $X$ разделяется на $n$ выборок $X_1, X_2, \dots, X_n$, причем $X_i$ и $X_j$ могут пересекаться при любых $i,j \in 1 \dots n$.

Идея данного подхода заключается в том, что в отличие от бустинга классификаторы не исправляют ошибки друг друга, а компенсируют их при голосовании~\cite{ensembles}. 

При этом результат голосования определяется посредством:
\begin{itemize}[label=---]
    \item консенсуса --- все классификаторы дают одинаковый ответ;
    \item простого большинства;
    \item взвешивания --- каждому класссификатору присваивается вес, учитываемый при принятии решения.
\end{itemize}

Схема бэггинга представлена на рис.~\ref{img:bagging}.

\includeimage{bagging}{f}{h}{\textwidth}{Схематическое представление алгоритма бэггинга}

Преимуществом данного метода перед стекингом является детерминированность результата: мета-модель в стекинге может переобучаться с течением времени, в то время как результат голосования в беггинге является детерминированным~\cite{ensembles}.

\section{Существующие методы}

По результатам проведенного иследования рынка, в настоящий момент не представлены общедоступные системы обнаружения надводных объектов, в связи с чем невозможно определить методы, использующиеся в оных. 

Тем не менее, в последние годы тема распознавания надводных объектов является объектом множества исследований, предлагающих разнообразные подходы к решению поставленных задач. Данные методы и будут рассмотрены далее.

\subsection{Разрешение изображений}

В настоящее время существующие методы можно разделить на две группы по разрешению снимков:

\begin{itemize}[label=---]
    \item VHR --- достигает разрешения в 0.5 метра и менее на 1 пиксель;
    \item MR --- достигает разрешения в несколько метров на 1 пиксель.
\end{itemize}

Одна из проблем методов, основанных на VHR --- доступность данных. В настоящее время изображения с таким разрешением могут быть получены лишь в нескольких источниках, использующих спутниковую съемку.

В тоже время, MR изображения могут быть получены, помимо прочего, с помощью съемки с дронов, что значительно удешевляет процесс сбора данных.

\subsection{R-CNN}

Первой CNN, разработанной для обнаружения объектов, является модель Region-based CNN, которая использует подходы на основе скользящего окна (sliding window)~\cite{r-cnn}.

Здесь авторы разделяют всю задачу на три модуля. В первом модуле из каждого входного изображения извлекаются RoI, которые могут содержать какой-либо объект (с помощью процедуры selective search), затем во втором модуле авторы используют аффинное искажение изображения, чтобы сделать все извлеченные RoI фиксированного размера (или фиксированного соотношения сторон), а затем пропускают эти искаженные RoI через AlexNet CNN для извлечения конечных признаков (векторов признаков фиксированного размера). Наконец, третий этап представляет собой набор линейных SVM (support vector machine), которые причисляют каждый вектор какому-либо классу и отдельный регрессор обрамляющих окон~\cite{r-cnn}.

Последующие версии алгоритма --- Fast R-CNN~\cite{fast-r-cnn} и Faster R-CNN~\cite{faster-r-cnn} --- призваны оптимизировать время работы алгоритма, а так же повысить точность распознавания. Так, в Faster R-CNN процедура selective search была заменена на сеть предложений регионов (RPN). RPN --- это CNN, используемая для создания высококачественных RoI.

CNN данного семейства активно используются в задачах, допускающих повышение времени работы системы ради повышения точности распознавания, т.е. в задачах, не относящихся к системам реального времени.

\subsubsection{Faster R-CNN}

Данная CNN является последним опубликованным улучшением алгоритма R-CNN. Основное отличие от предшествующей Fast CNN является замена процедуры генерации претендентов избирательным поиском на нейронную сеть, которая использует имеющуюся карту особенностей~\cite{faster-r-cnn}.

Архитектура работы Faster R–CNN представлена на рисунке

\includeimage{faster-r-cnn}{f}{h}{\textwidth}{Архитектура Faster R–CNN}

Внесенные изменения позволяют повысить быстродействие распознавания образов на изображении вплоть до десяти раз в сравнении с предшествующей версией алгоритма~\cite{faster-r-cnn}.

\subsection{YOLO}

Алгоритм YOLO (You Only Look Once) является одноэтапным и может непосредственно распознавать объекты, а также их местоположение с помощью сквозной обученной модели CNN~\cite{yolo-review}.

В исходном алгоритме YOLO входное изображение разбивается на фиксированное число сеток, а затем из каждой сетки предсказывается фиксированное число местоположений обрамляющих окон (bounding boxes) и вероятностей. Затем используется пороговое значение для выбора и определения местоположения объекта на изображении~\cite{yolo-review}.

Основной проблемой YOLO является более низкая точность при распознавании больших и малых объектов, а так же присущая всем одноэтапным алгоритмам потеря точности распознавания в сравнении с двухэтапными алгоритмами~\cite{yolo-review}.

Данное семейство алгоритмов включает в себя множество оптимизаций оригинального YOLO, причем последней опубликованной является YOLOv8~\cite{yolo-review-2023}, представленная в 2023 году.

Начиная с YOLOv4, варианты алгоритма имеют малозначительные изменения, призванные улучшить его характеристики в контексте конкретных задач~\cite{yolov3-ships}. Например, одним из вариантов развития актуальной на тот момент времени YOLOv3~\cite{yolov3} является YOLOv3~tiny~\cite{yolov3-tiny}, разработанная для решения задачи распознавания судов и кораблей в режиме реального времени.

Данное семейство CNN активно используется в задачах распознавания надводных объектов. В первую очередь, это связано с малыми затратами времени на обработку изображения, в сравнении с другими алгоритмами. Так же, достоинством YOLO является, возможность распознавать большое число объектов на одном изображении~\cite{yolo9000}.

\subsubsection{YOLOv5}

В настоящее время данная CNN, разработанная Ultralytics в 2020 году, пользуется большой популярностью. Данная версия была опубликована вскоре после выхода YOLOv4, однако основным ее отличем стало использование PyTorch~\cite{pytorch} вместо Darknet~\cite{darknet} в качестве средства реализации. Поддержка и развитие осуществляется за счет сообщества, в связи с чем до сих пор не опубликована научная работа, описывающая данную CNN~\cite{yolo-review-2023}.

В момент написания данной работы, актуальной является версия v7.0. Кроме того, существуют следующие версии масштабирования CNN: YOLOv5n (nano), YOLOv5s (small), YOLOv5m (medium), YOLOv5l (large), YOLOv5x (extra large).

Отдельно стоит отметить, что перечисленные выше версии данной CNN имеют так же варианты с различным числом выходных слоев для объектов --- от P3 до P6, соответственно, и обозначаемые, например YOLOv5s6 для YOLOv5s с P6.

В зависимости от версии масштабирования изменяется точность и время обработки единичного изображения, соответственно~\cite{yolo-review-2023}.

Архитектура YOLOv5 состоит из следующих частей:
\begin{itemize}[label=---]
    \item Backbone --- CSP-Darknet53;
    \item Neck --- SPP и PANet;
    \item Head --- аналогично YOLOv4, состоит из сверточных слоев.
\end{itemize}

\includeimage{yolov5}{f}{h}{\textwidth}{Архитектура YOLOv5}

\includeimage{yolov5-details}{f}{h}{0.7\textwidth}{Архитектура YOLOv5}

\subsubsection{YOLOv8}

Данная CNN так же разработана Ultralytics. В ней применены несколько новых подходов как к процессу обучения, так и к самой архитектуре сети.

Аналогично YOLOv5, существует 5 масштабных версий от YOLOv8n до YOLOv8x включительно.

К сожалению, из-за новизны данной архитектуры, еще не были опубликованы результаты сравнения точности работы и производительности в сравнении с предыдующими версиями и, в частности, с YOLOv5.

Исходя из представленной разработчиком информации, данная CNN имеет более высокую точность обнаружения объектов, однако уступает прелылушей версии в быстродействии.

\includeimage{yolov8}{f}{h}{\textwidth}{Архитектура YOLOv8}

\includeimage{yolov8-details}{f}{h}{\textwidth}{Архитектура YOLOv8}


\subsection{Параметры для сравнения}

Для оценки работы нейронной сети используется величина AP (Average Precision), вычисляемая следующим образом:

\begin{equation}
	AP = \frac{\text{кол-во верно распознанных объектов}}{\text{общее кол-во распознанных объектов}}.
\end{equation}

Отметим, что AP вычисляется для объектов одного класса, в связи с чем для классификаторов с несколькими возможными классами объектов используется величина mAP (англ. mean AP) --- среднее значение AP.

Кроме того, данную величину принято оценивать в зависимости от IoU (Intersection over Union), вычисляемую по формуле:

\begin{equation}
	IoU = \frac{\text{площадь пересечения областей}}{\text{площадь объединения областей}}.
\end{equation}

IoU описывает то, насколько предсказанные CNN обрамляющие окна близки к <<истинным>>. Данная величина принимает значения в диапазоне $[0;1]$, соответственно.

\subsection{Сравнение рассмотренных методов}

\subsubsection*{YOLOv5x}

На основании датасета MS COCO test-dev 2017, достигается значение AP равное 50.7\% при размере входного изображения в 640 пикслелей. При увеличении размера изображения до 1536 пикселей AP достигает 55.8\%~\cite{yolo-review-2023}. 

Кроме того, использование батча с размером 32, достигается производителльность вплоть до 200 FPS при использовании NVIDIA V100~\cite{nvidia-v100}.

\subsubsection*{YOLOv8x}

Заявляется, что при использовании того же датасета YOLOv8x достигает AP равного 53.9\% при размере входного изображения в 640 пикслелей (в сравнении с 50.7\% для YOLOv5x)~\cite{yolo-review-2023}.

Производительность данной CNN достигает 280 FPS при использовании NVIDIA~A100~\cite{nvidia-a100} и TensorRT~\cite{nvidia-tensorrt}.

\subsubsection*{Сравнение методов}

Приведенные в таблице результаты получены при размере входного изображения равном $640 \times 640$ пикселей. Измерения проводились на основании датасета COCO~\cite{coco-benchmark} с использованием GPU NVIDIA~GeForce~RTX~4090~\cite{rtx4090}.

\begin{table}[!h]
    \small
    \begin{center}
        \caption{Сравнение рассмотренных методов}
        \label{tbl:cmp-by-ap}
        \begin{tabular}{|l|cc|c|c|c|}
            \hline
            CNN & \multicolumn{2}{c|}{$mAP_{IoU}$} & Параметры, & FLOPs, & FPS \\
                & $mAP_{0.5}$ & $mAP_{0.5:0.95}$    & млн. шт.   & млрд.  & \\\hline

            Faster R-CNN & 62.5 & ---  & 53   & 888   & --- \\
            YOLOv5n      & 45.7 & 28.0 & 1.9  & 4.5   & 934 \\
            YOLOv5x      & 50.7 & 68.9 & 86.7 & 205.7 & 252 \\
            YOLOv8n      & 37.3 & 50.4 & 3.2  & 8.7   & 1163 \\
            YOLOv8x      & 53.9 & ---  & 68.2 & 257.8 & 236 \\
            \hline
        \end{tabular}
    \end{center}
\end{table}

\section{Метод распознавания надводных объектов с аэрофотоснимков с использованием нейронных сетей}

\section{Формализованная постановка задачи}

\includeimage{method}{f}{h}{0.8\textwidth}{Общий вид метода}

\section{Выбор данных для обучения модели}

~\cite{kaggle-airbus}
