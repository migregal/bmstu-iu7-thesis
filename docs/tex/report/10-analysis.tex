\chapter{Аналитический раздел}

\section{Предметная область}

В настояще время все больше внимания привлекает тема автоматизации судоходства, а так же общее повышение уровня безопасности в процессе эксплуатации судов.

Методы распознавания различных надводных объектов имеют особое значение в данном контексте, так как позволяют решить множество проблем: избежание столкновений судов, осуществление автономного плавания и пр.~\cite{ship-detection}.

Не менее важной является задача распознавания малых надводных объектов, поскольку традиционные методы обнаружения, основанные на использовании радара, не подходят для задачи обнаружения близко расположенных и малых объектов~\cite{small-ship-detection}.

Кроме того, обнаружение активности рыболовецких судов по-прежнему является сложной задачей для многих стран, расположенных на архипелагах, например --- Индонезии. В настоящее время для мониторинга огромной морской акватории используется технология, использующая датчики SAR для обнаружения кораблей, разрабатываемая с 1985 года. Однако стоимость использования данной технологии является одним из основных препятствий для дальнейшего развития~\cite{boats-recognition}.

\section{Нейронные сети}

ANN определяется как массово параллельный распределенный процессор, состоящий из простых процессорных блоков, который обладает естественной склонностью накапливать эмпирические знания~\cite{ann}. 

Их название и структура вдохновлены человеческим мозгом, а алгоритм работы основывается на способе, которым биологические нейроны передают сигналы друг другу.

В общем случае ANN включает в себя входной слой, выходной (или целевой) слой и, между ними, скрытый слой. Слои соединены через узлы (искусственные нейроны). Эти соединения образуют <<сеть>> --- нейронную сеть --- из взаимосвязанных узлов. Пример приведен на рисунке~\ref{img:network}.

\includeimage{network}{f}{h}{0.7\textwidth}{Пример схемы ANN}

В общем случае искусственный нейрон можно представить в виде регрессионной модели \cite{activationfuncs}, состоящей из входных данных, весовых коэффициентов, смещения (или порогового значения) и выходных данных. Эту модель можно описать следующей формулой:

\begin{equation}
	\label{eq:nn0}
	\hat{y} = \sum_{i=1}^{n}w_ix_i + w_0,
\end{equation}

В качестве функции активации можно использовать: ступенчатую, линейную функции, сигмоиду, ReLu и другие~\cite{activationfuncs}.

Модель искусственного нейрона приведена на рисунке~\ref{img:neuron}.

\includeimage{neuron}{f}{h}{0.7\textwidth}{Общая схема искусственного нейрона}

Данное представление применимо к любому виду нейронных сетей --- вне зависимости от типа, нейронные сети реализуются путем упорядочивания нейронов в слои и последующим связыванием соответствующих слоев между собой~\cite{ann}.

В процессе обучения нейронной сети используется так называемая обучающая выборка --- заранее подготовленный набор данных, отражающий суть рассматриваемой предметной области~\cite{ann}. В зависимости от содержимого обучающей выборки результирующие весовые конфигурации нейронной сети (т.~е. веса связей между нейронами, а так же смещения отдельно взятых нейронов) могут отличаться~\cite{ann}. В связи с этим одна и та же структура нейронной сети может переиспользована для работы в различных предметных областях.

\section{Сверточные нейронные сети}

Одним из основных видов нейронных сетей, применяемых для распознавания является CNN~\cite{cnn}.

CNN представляет собой тип ANN, которая имеет архитектуру с глубокой обратной связью и выделяется на фоне остальных ANN с полносвязными слоями своей способностью к обобщению. CNN работает с сильно абстрагированными характеристиками объектов, особенно это касается пространственных данных, что позволяет добиться более эффективно идентифицировать объекты в сравнении с другими типами ANN~\cite{cnn}. Одним из отличительных свойств CNN является способность к фильтрации посторонних шумов во входных данных.

Модель CNN состоит из конечного набора уровней обработки, которые могут изучать различные характеристики входных данных (например, изображения) с несколькими уровнями абстракции. Начальные уровни изучают и извлекают высокоуровневые свойства, а более глубокие уровни изучают и извлекают более низкоуровневые свойства. Концептуальная модель CNN представлена на рисунке~\ref{img:cnn-conceptual-model}.

\includeimage{cnn-conceptual-model}{f}{h}{0.7\textwidth}{Концептуальная модель CNN}

Существующие архитектуры CNN для обнаружения объектов на изображениях можно разделить на две категории: одноэтапные (one-stage) и двухэтапные (two-stage)~\cite{review-on-one-stage-object-detection}.    

\subsection{Свертка}

\subsubsection*{Ядро}

Прежде, чем рассматривать процесс свертки, необходимо определить понятие <<ядро>>, используемое при свертке. Ядро представляет собой матрицу из дискретных значений или чисел, где каждое значение известно как вес этого ядра. Пример двухмерного ядра приведен на рисунке~\ref{img:convolution-kernel}.

\includeimage{convolution-kernel}{f}{h}{0.15\textwidth}{Пример двумерного ядра с размерностью $2 \times 2$}

Ядро инициализируется случайными значениями, которые изменяются в ходе обучения CNN.

\subsubsection*{Процесс свертки}

Свертка --- это операция над парой матриц $A(n_x, n_y)$ и $B(m_x, m_y)$, $m_x  \le n_x$, $m_y \le n_y$, результатом которой является матрица 

\begin{equation}
C(n_x - m_x +1, n_y - m_y + 1) = A * B,
\end{equation}

каждый элемент которой является скалярным произведением матрицы $B$ (ядра свертки) и некоторой подматрицы $A$ такого же размера.

Т.~е. элемент матрицы C вычисляется следующим образом:
\begin{equation}
C_{i,j} = \Sigma_{u=0}^{m_x-1} \Sigma_{v=0}^{m_y-1} A_{i+u,j+v}B_{u,v}.
\end{equation}

\subsubsection*{Пример}

Разберем пример свертки для изображения в градациях серого, т.к. такое изображение содержит лишь один канал, передаваемый на вход CNN.

Пусть дано изображение, представленное на рисунке~\ref{img:convolution-input-example}.

\includeimage{convolution-input-example}{f}{h}{0.25\textwidth}{Пример изображения в градациях серого с размерностью $4 \times 4$}

Далее рассмотрим первые два шага процесса свертки, представленные на рисунках~\ref{img:convolution-example-1}~и~\ref{img:convolution-example-2}, соответственно.

\includeimage{convolution-example-1}{f}{h}{0.7\textwidth}{Пример свертки изображения в градациях серого с размерностью $4 \times 4$}

\includeimage{convolution-example-2}{f}{h}{0.75\textwidth}{Пример свертки изображения в градациях серого с размерностью $4 \times 4$}

Аналогичным образом свертка продолжается до полного заполнения результирующей матрицы. Стоит отметить, что, в зависимости от размеров окна и перекрытия окон, будет меняться размер результирующей матрицы.

\subsection{Двухэтапные CNN}

В таких нейросетевых алгоритмах выделяют два этапа: поиска RoI (англ. Candidate Region Extraction) на изображении и последующей классификации RoI, найденных на первом этапе. При этом под RoI на изображении подразумеваются зоны, потенциально содержащие искомые объекты~\cite{overview-of-two-stage-object-detection}. 

\includeimage{two-step-cnn}{f}{h}{0.8\textwidth}{Схема работы двухэтапного алгоритма}

Стоит отметить, что первый этап может происходить без использования нейронных сетей. Для этого можно использовать информацию о контрасте, ключевые точки или перебор всех возможных положений объекта с помощью процедуры~\texttt{selective search}~\cite{realtime-recognition-algorythm}.

RoI, полученные вышеперечисленными методами, могут обладать серьезными недостатками, например:
\begin{itemize}[label=---]
    \item содержать слишком большое количество фона;
    \item содержать лишь небольшую часть объекта;
    \item содержать более одного объекта.
\end{itemize}

В связи с этим на первом этапе более предпочтительным методом является применение CNN, не содержащих полносвязных слоев~\cite{realtime-recognition-algorythm}.

На втором этапе CNN применяются к обнаруженным RoI.

Преимуществом данных алгоритмов является высокая точность распознавания объектов, однако, платой за это является время, необходимое для выделения <<подозрительных>> зон на изображении~\cite{overview-of-two-stage-object-detection}.

\subsection{Одноэтапные CNN}

Данные нейросетевые алгоритмы не включают в себя этап поиска RoI на изображении.

\includeimage{one-step-cnn}{f}{h}{0.8\textwidth}{Схема работы одноэтапного алгоритма}

Преимуществами одноэтапных алгоритмов являются их простота и относительно высокая скорость работы. К недостаткам же можно отнести более низкую точность детектирования объектов по сравнению с двухэтапными алгоритмами, а также меньшую гибкость алгоритма с точки зрения рассматриваемых изображений~\cite{review-on-one-stage-object-detection}.

В настоящее время в CNN принято выделять несколько частей, использующихся в процессе работы. Общий вид современного одноэтапного детектора представлен на рисунке~\ref{img:modern-one-stage-detector}.

\includeimage{modern-one-stage-detector}{f}{h}{\textwidth}{Общий вид современного одноэтапного детектора}

Основными частями такой CNN являются:
\begin{itemize}[label=---]
    \item Backbone;
    \item Neck;
    \item Dense Prediction.
\end{itemize}

\section{Ансамбли}

Ансамбль --- это набор слабых экспертов, выполняющих распознавание произвольного объекта $x \in X$, конечный результат которого рассчитывается на основе результатов работы составляющих слабых экспертов. Слабыми экспертами в ансамбле могут выступать в том числе и другие ансамбли.

Тем не менее, ансамбль на основе нескольких моделей, построенных независимо друг от друга, в общем случае будет иметь более низкое качество, чем ансамбль на основе моделей, построенных с использованием специальных алгоритмов~\cite{ensembles}.

К этим алгоритмам относятся стекинг, бустинг и бэггинг, позволяющие существенно повысить качество классификации~\cite{ensembles}.

\subsection{Стекинг}

Стекинг подразумевает параллельные обучение и работу всех слабых экспертов, т.~е. классификаторы не зависят друг от друга~\cite{ensembles}. 

Схема стекинга представлена на рис.~\ref{img:stacking}.

\includeimage{stacking}{f}{h}{\textwidth}{Схематическое представление алгоритма стекинга}

Обучающая выборка $X$ разделяется на $n$ случайных равновеликих частей (фолдов).

Для объекта из выборки, находящегося в $k$-ом фолде, производится предсказание слабыми экспертами, обученными на $k-1$ фолдах. Данный процесс итеративен и происходит для каждого фолда.

Таким образом, для каждого объекта обучающей выборки создается набор прогнозов слабых экспертов. Далее, на сформированных наборах прогнозов происходит обучение метамодели~\cite{ensembles}.

\subsection{Бустинг}

При использовании бустинга, каждый последующий алгоритм, входящий в ансамбль, стремится компенсировать недостатки композиции всех предыдущих алгоритмов~\cite{ensembles}.

\subsubsection*{Формальная постановка задачи}

Пусть $h(a, \overrightarrow{x})$ --- слабый эксперт, где $\overrightarrow{x}$ --- это вектор параметров. Необходимо найти следующий алгоритм:

\begin{equation}
H_T(a) = \Sigma_{t=1}^T b_th(a, \overrightarrow{x}),
\end{equation}

где $b_i \in \mathbb{R}$ --- коэффициенты, при которых

\begin{equation}
Q = \Sigma_iL(H_T(a_i), y_i) \to min,
\end{equation}

где $L$ --- функция потерь. 

Так как в общем случае процесс вычисления $\{(\overrightarrow{x}_t, b_t)\}_{t=1}^T$ нетривиален, решение находят пошагово:

\begin{equation}
H_t(a) = H_{t-1}(a) + b_th(a, \overrightarrow{x}).
\end{equation}

Схема бустинга представлена на рис.~\ref{img:boosting}.

\includeimage{boosting}{f}{h}{\textwidth}{Схематическое представление алгоритма бустинга}

\subsubsection*{Алгоритмы}

Среди наиболле часто используемых алгоритмов бустинга: AdaBoost и BrownBoost~\cite{ensembles}.

\subsection{Бэггинг}

В бэггинге все слабые эксперты обучаются и работают параллельно, т.~е. независимо друг от друга. При этом обучающая выборка $X$ разделяется на $n$ выборок $X_1, X_2, \dots, X_n$, причем $X_i$ и $X_j$ могут пересекаться при любых $i,j \in 1 \dots n$.

Идея данного подхода заключается в том, что в отличие от бустинга классификаторы не исправляют ошибки друг друга, а компенсируют их при голосовании~\cite{ensembles}. 

При этом результат голосования определяется посредством:
\begin{itemize}[label=---]
    \item консенсуса --- все классификаторы дают одинаковый ответ;
    \item простого большинства;
    \item взвешивания --- каждому классификатору присваивается вес, учитываемый при принятии решения.
\end{itemize}

Схема бэггинга представлена на рис.~\ref{img:bagging}.

\includeimage{bagging}{f}{h}{\textwidth}{Схематическое представление алгоритма бэггинга}

Преимуществом данного метода перед стекингом является детерминированность результата: мета-модель в стекинге может переобучаться с течением времени, в то время как результат голосования в беггинге является детерминированным~\cite{ensembles}.

\section{Существующие методы}

По результатам проведенного исследования рынка, в настоящий момент не представлены общедоступные системы распознавания надводных объектов, в связи с чем невозможно определить методы, использующиеся в оных. 

Тем не менее, в последние годы тема распознавания надводных объектов является объектом множества исследований, предлагающих разнообразные подходы к решению поставленных задач. Данные методы и будут рассмотрены далее.

\subsection{R-CNN}

Первой CNN, разработанной для распознавания объектов, является модель Region-based CNN, которая использует подходы на основе скользящего окна (sliding window)~\cite{r-cnn}.

Здесь авторы разделяют всю задачу на три модуля. В первом модуле из каждого входного изображения извлекаются RoI, которые могут содержать какой-либо объект (с помощью процедуры selective search), затем во втором модуле авторы используют аффинное искажение изображения, чтобы сделать все извлеченные RoI фиксированного размера (или фиксированного соотношения сторон), а затем пропускают эти искаженные RoI через AlexNet CNN для извлечения конечных признаков (векторов признаков фиксированного размера). Наконец, третий этап представляет собой набор линейных SVM (support vector machine), которые причисляют каждый вектор какому-либо классу и отдельный регрессор обрамляющих окон~\cite{r-cnn}.

Последующие версии алгоритма --- Fast R-CNN~\cite{fast-r-cnn} и Faster R-CNN~\cite{faster-r-cnn} --- призваны оптимизировать время работы алгоритма, а так же повысить точность распознавания. Так, в Faster R-CNN процедура selective search была заменена на сеть предложений регионов (RPN). RPN --- это CNN, используемая для создания высококачественных RoI.

CNN данного семейства активно используются в задачах, допускающих повышение времени работы системы ради повышения точности распознавания, т.е. в задачах, не относящихся к системам реального времени.

\subsubsection{Faster R-CNN}

Данная CNN является последним опубликованным улучшением алгоритма R-CNN. Основное отличие от предшествующей Fast CNN является замена процедуры генерации претендентов избирательным поиском на нейронную сеть, которая использует имеющуюся карту особенностей~\cite{faster-r-cnn}.

Архитектура работы Faster R–CNN представлена на рисунке

\includeimage{faster-r-cnn}{f}{h}{\textwidth}{Архитектура Faster R–CNN}

Внесенные изменения позволяют повысить быстродействие распознавания образов на изображении вплоть до десяти раз в сравнении с предшествующей версией алгоритма~\cite{faster-r-cnn}.

\subsection{YOLO}

Алгоритм YOLO (You Only Look Once) является одноэтапным и может непосредственно распознавать объекты, а также их местоположение с помощью сквозной обученной модели CNN~\cite{yolo-review}.

В исходном алгоритме YOLO входное изображение разбивается на фиксированное число сеток, а затем из каждой сетки предсказывается фиксированное число местоположений обрамляющих окон (bounding boxes) и вероятностей. Затем используется пороговое значение для выбора и определения местоположения объекта на изображении~\cite{yolo-review}.

Основной проблемой YOLO является более низкая точность при распознавании больших и малых объектов, а так же присущая всем одноэтапным алгоритмам потеря точности распознавания в сравнении с двухэтапными алгоритмами~\cite{yolo-review}.

Данное семейство алгоритмов включает в себя множество оптимизаций оригинального YOLO, причем последней опубликованной является YOLOv8~\cite{yolo-review-2023}, представленная в 2023 году.

Начиная с YOLOv4, варианты алгоритма имеют малозначительные изменения, призванные улучшить его характеристики в контексте конкретных задач~\cite{yolov3-ships}. Например, одним из вариантов развития актуальной на тот момент времени YOLOv3~\cite{yolov3} является YOLOv3~tiny~\cite{yolov3-tiny}, разработанная для решения задачи распознавания судов и кораблей в режиме реального времени.

Данное семейство CNN активно используется в задачах распознавания надводных объектов. В первую очередь, это связано с малыми затратами времени на обработку изображения, в сравнении с другими алгоритмами. Так же, достоинством YOLO является возможность распознавать большое число объектов на одном изображении~\cite{yolo9000}.

\subsubsection{YOLOv5}

В настоящее время данная CNN, разработанная Ultralytics в 2020 году, пользуется большой популярностью. Данная версия была опубликована вскоре после выхода YOLOv4, однако основным ее отличием стало использование PyTorch~\cite{pytorch} вместо Darknet~\cite{darknet} в качестве средства реализации. Поддержка и развитие осуществляется за счет сообщества, в связи с чем до сих пор не опубликована научная работа, описывающая данную CNN~\cite{yolo-review-2023}.

В момент написания данной работы, актуальной является версия v7.0. Кроме того, существуют следующие версии масштабирования CNN: YOLOv5n (nano), YOLOv5s (small), YOLOv5m (medium), YOLOv5l (large), YOLOv5x (extra large).

Отдельно стоит отметить, что перечисленные выше версии данной CNN имеют так же варианты с различным числом выходных слоев для объектов --- от P3 до P6, соответственно, и обозначаемые, например YOLOv5s6 для YOLOv5s с P6.

В зависимости от версии масштабирования изменяется точность и время обработки единичного изображения, соответственно~\cite{yolo-review-2023}.

Архитектура YOLOv5 состоит из следующих частей: CSP-Darknet53 в качестве Backbone, SPPF и PANet в качестве Neck и Head аналогичный YOLOv4. В общем виде YOLOv5 представлена на рисунках~\ref{img:yolov5}~и~\ref{img:yolov5-details}.

\includeimage{yolov5}{f}{h}{0.9\textwidth}{Архитектура YOLOv5. Часть 1}

\includeimage{yolov5-details}{f}{h}{0.6\textwidth}{Архитектура YOLOv5. Часть 2}

\subsubsection{YOLOv8}

Данная CNN так же разработана Ultralytics. В ней применены несколько новых подходов как к процессу обучения, так и к самой архитектуре сети.

Аналогично YOLOv5, существует 5 масштабных версий от YOLOv8n до YOLOv8x включительно.

К сожалению, из-за новизны данной архитектуры, еще не были опубликованы какие-либо работы, сравнивающие точность работы и производительность новой архитектуры с предыдущими версиями и, в частности, с YOLOv5.

Исходя из представленной разработчиком информации, данная CNN имеет более высокую точность распознавания объектов, однако уступает предыдущей версии в быстродействии.

Общий вид данной архитектуры представлен на рисунках~\ref{img:yolov8}~и~\ref{img:yolov8-details}.

\includeimage{yolov8}{f}{h}{\textwidth}{Архитектура YOLOv8. Часть 1}

\includeimage{yolov8-details}{f}{h}{\textwidth}{Архитектура YOLOv8. Часть 2}


\subsection{Параметры для сравнения}

Для оценки точности работы нейронной сети используется величина AP (Average Precision), вычисляемая следующим образом:

\begin{equation}
	AP = \frac{\text{кол-во верно распознанных объектов}}{\text{общее кол-во распознанных объектов}}.
\end{equation}

Отметим, что AP вычисляется для объектов одного класса, в связи с чем для классификаторов с несколькими возможными классами объектов используется величина mAP (англ. mean AP) --- среднее значение AP.

Кроме того, данную величину принято оценивать в зависимости от IoU (Intersection over Union), вычисляемую по формуле:

\begin{equation}
	IoU = \frac{\text{площадь пересечения областей}}{\text{площадь объединения областей}}.
\end{equation}

IoU описывает то, насколько предсказанные CNN обрамляющие окна близки к <<истинным>>. Данная величина принимает значения в диапазоне $[0;1]$, соответственно.

\subsection{Сравнение рассмотренных методов}

\subsubsection*{YOLOv5x}

На основании датасета MS COCO test-dev 2017, достигается значение AP равное 50.7\% при размере входного изображения в 640 пикселей. При увеличении размера изображения до 1536 пикселей AP достигает 55.8\%~\cite{yolo-review-2023}. 

При этом, производительность CNN составляет вплоть до 200 FPS при использовании NVIDIA V100~\cite{nvidia-v100}.

\subsubsection*{YOLOv8x}

Заявляется, что при использовании того же датасета YOLOv8x достигает AP равного 53.9\% при размере входного изображения в 640 пикселей (в сравнении с 50.7\% для YOLOv5x)~\cite{yolo-review-2023}.

Производительность данной CNN достигает 280 FPS при использовании NVIDIA~A100~\cite{nvidia-a100} и TensorRT~\cite{nvidia-tensorrt}.

\subsubsection*{Сравнение методов}

Приведенные в таблице результаты получены при размере входного изображения равном $640 \times 640$ пикселей. Измерения проводились на основании датасета COCO~\cite{coco-benchmark} с использованием GPU NVIDIA~GeForce~RTX~4090~\cite{rtx4090}.

\begin{table}[!h]
    \small
    \begin{center}
        \caption{Сравнение рассмотренных методов}
        \label{tbl:cmp-by-ap}
        \begin{tabular}{|l|cc|c|c|c|}
            \hline
            CNN & \multicolumn{2}{c|}{$mAP_{IoU}$} & Параметры, & FLOPs, & FPS \\
                & $mAP_{0.5}$ & $mAP_{0.5:0.95}$    & млн. шт.   & млрд.  & \\\hline

            Faster R-CNN & 62.5 & ---  & 53   & 888   & < 20 \\
            YOLOv5n      & 45.7 & 28.0 & 1.9  & 4.5   & 934 \\
            YOLOv5x      & 50.7 & 68.9 & 86.7 & 205.7 & 252 \\
            YOLOv8n      & 37.3 & 50.4 & 3.2  & 8.7   & 1163 \\
            YOLOv8x      & 53.9 & ---  & 68.2 & 257.8 & 236 \\
            \hline
        \end{tabular}
    \end{center}
\end{table}


\section{Метод распознавания надводных объектов с аэрофотоснимков с использованием нейронных сетей}

Распознавание надводного объекта на основе единственного изображения возможно с использованием CNN, однако при этом надводный объект должен быть различим, что накладывает ограничения на условия работы и разрешение входных данных.

В связи с тем, что размеры надводных объектов сильно варьируются (например, размеры морского буя и сухогрузного судна) и могут быть крайне малы при съемке с большого расстояния, метод, разрабатываемый в рамках данной работы должен иметь возможность распознавания лишь относительно крупных объектов. Такие ограничения связаны, в первую очередь, с зашумленностью получаемых снимков из-за погодных условий и контекста изображений.

Кроме того, аэрофотосъемку можно грубо разделить на две категории: съемка с большой высоты (например, с использованием искусственных спутников) и съемка с малой высоты, например, с использованием БПЛА, с различных ракурсов.

Таким образом разрабатываемый метод должен решать две описанные выше задачи --- распознавать надводные объекты снятые с различных высот и ракурсов.

\section{Формализованная постановка задачи}

Цель работы --- разработка метода распознавания надводных объектов с аэрофотоснимков. Для достижения этой цели необходимо решить следующие задачи:
\begin{itemize}[label=---]
    \item разработать соответствующий метод;
    \item реализовать разработанный метод;
    \item оценить результаты работы метода в зависимости от различных параметров системы.
\end{itemize}

Входными данными метода является изображение. Результатом работы являются объекты распознавания.

На метод накладываются следующие ограничения:
\begin{itemize}[label=---]
    \item входные данные --- фотоснимок в формате PNG, JPG, JPEG;
    \item размерность входного изображения --- не ниже $640 \times 640$ и не более $1280 \times 1280$ пикселей;
    \item разрешение входного изображения --- от 0.5 до 15 метров/пиксель;
    \item работа только в дневное время суток (так как метод, разработанный для <<ночной>> работы может обладать совершенно другими свойствами);
    \item распознавание только различимых объектов на изображении.
\end{itemize}

На рисунке~\ref{img:method} представлена диаграмма, описывающая общий вид метода распознавания надводных объектов с использованием нейронных сетей.

\includeimage{method}{f}{h}{0.8\textwidth}{Общий вид метода}

\section{Выбор данных для обучения модели}

\subsection{Разрешение изображений}

В настоящее время существующие методы можно разделить на две группы по разрешению используемых в процессе обучения и работы снимков:

\begin{itemize}[label=---]
    \item VHR --- достигает разрешения в 0.5 метра и менее на 1 пиксель;
    \item MR --- достигает разрешения в несколько метров на 1 пиксель.
\end{itemize}

Одна из проблем методов, основанных на VHR --- сбор данных. В настоящее время изображения с таким разрешением могут быть получены лишь в нескольких источниках, использующих спутниковую съемку.

В тоже время, MR изображения могут быть получены, помимо прочего, с помощью съемки с БПЛА, что может значительно удешевить процесс сбора данных в сравнении с VHR.

Тем не менее, выборки снимков надводных объектов, находящиеся в открытом доступе, преимущественно состоят из VHR снимков, что объясняется сложностью проведения съемок посредством БПЛА, связанных с ограничениями в ряде регионов и стран.

\subsection{Требования к данным}

Для того, чтобы сделать вывод о корректности результата обучения модели, данные, использующиеся в процессе обучения должны удовлетворять нескольким требованиям:
\begin{itemize}[label=---]
    \item полнота --- в выборке должны быть представлены различные расположения надводных объектов. Например судно расположенное в порту и в открытом море;
    \item количество --- снимков в выборке должно быть достаточно для того, чтобы модель на одном и том же изображении не давала разных результатов;
    \item единообразие --- снимки в выборке должны быть схожего формата для исключения неоднозначных результатов.
\end{itemize}

\section{Вывод}