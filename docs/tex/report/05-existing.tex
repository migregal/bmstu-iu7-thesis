\chapter{Существующие методы}

\section{Скрытые Марковские модели}

Одним из статических методов распознавания объектов с изображений являются скрытые Марковские модели с дискретным временем. HMM -- это вероятностная модель, построенная на цепях Маркова, в частности, цепях Маркова с дискретным временем~\cite{hmm-early-classification}.

HMM используют статистические свойства сигналов и учитывают непосредственно их пространственные характеристики, поэтому они широко применяются в задачах распознавания. Входным сигналом для HMM служит последовательность $O = o_1,o_2,\,\dots,\,o_T$, где $o_i$ - сигнал, наблюдаемый в момент времени $i=\overline{1,\,T}$~\cite{hmm-early-classification}.

На рисунке~\ref{img:hmm} приведены сам процесс (модель) $x(\tau)$ и наблюдаемые неизвестные параметры $y(\tau)$.

\imgw{hmm}{h}{0.6\textwidth}{Скрытая Марковская модель}

Для задания HMM требуется обеспечить процесс перехода между состояниями, связи между процессом $x(\tau)$ и наблюдаемыми неизвестными параметрами $y(\tau)$, а также знать исходное распределение состояний $p_0(x)$~\cite{hmm-ship-behavior-prediction}.

Последовательность наблюдений $O$ может извлекаться из изображения различными способами. В силу этого описательные способности полученных моделей могут различаться. Обычно прибегают к методу сканирования изображения прямоугольным окном, причем размерность перекрытия окон при сканировании подбирается экспериментально. Затем, для уменьшения пространства признаков каждый извлеченный блок проходит некоторую обработку. Для задачи распознавания с изображений чаще всего используются преобразование Карунена-Лоэва (англ. KLT) или дискретно-косинусное преобразование (англ DCT)~\cite{hmm-intro}.

Несмотря на то, что HMM может применяться в качестве самостоятельного классификатора,
сложность задания моделируемого процесса все еще остается существенной проблемой. Для ее решения, можно использовать CNN, предварительно пропустив входное изобрежение через нее. Это позволит выделять векторы признаков с меньшим пространством~\cite{hmm-and-cnn}.

\section{Метод k-ближайших соседей}

kNN -- это один из самых простых, но эффективных методов машинного обучения, чаще всего использующийся в задачах классфикация, несмотря на то, что данный метод подходит и для задач регрессии. В kNN объект классифицируется на основе оценки k-ближайших соседей в n-мерном пространстве известных образцов~\cite{knn-introduction}.

Пример работы данного алгоритма для двухмерного случая приведен на рисунке~\ref{img:knn}.

\imgw{knn}{h}{0.3\textwidth}{Пример использования kNN для двухмерного случая с $k=5$}

Существует множество оптимизаций, призванных улучшить данный метод. Однако у kNN остаются его наиболее сложно решаемые проблемы -- определение значения K, размер памяти, необходимый при работе с большими объемами данных, а так же выбор подходящего способа определения расстояния между объектами в конкретной задаче~\cite{knn-brief}. 

\section{Нейросетевые алгоритмы}

\subsection{Двухэтапные CNN}

\subsubsection*{R-CNN}

Первой CNN, разработанной для обнаружения объектов, является модель Region-based CNN, которая использует подходы на основе скользящего окна (sliding window) для обнаружения объектов~\cite{r-cnn}.

Здесь авторы разделяют всю задачу на три модуля. В первом модуле из каждого входного изображения извлекаются RoI, которые могут содержать какой-либо объект (с помощью процедуры selective search), затем во втором модуле авторы используют аффинное искажение изображения, чтобы сделать все извлеченные RoI фиксированного размера (или фиксированного соотношения сторон), а затем пропускают эти искаженные RoI через AlexNet CNN для извлечения конечных признаков (векторов признаков фиксированного размера). Наконец, третий этап представляет собой набор линейных SVM (support vector machine), которые причисляют каждый вектор какому-либо классу и отдельный регрессор обрамляющих окон~\cite{r-cnn}.

Последующие версии алгоритма -- Fast R-CNN~\cite{fast-r-cnn} и Faster R-CNN~\cite{faster-r-cnn} -- призваны оптимизировать время работы алгоритма, а так же повысить точность распознавания. Так, в Faster R-CNN процедура selective search была заменена на сеть предложений регионов (RPN). RPN -- это CNN, используемая для создания высококачественных RoI.

\subsection{Одноэтапные CNN}

\subsubsection*{YOLO}

Алгоритм YOLO (You Only Look Once) является одноэтапным и может непосредственно распознавать объекты, а также их местоположение с помощью сквозной обученной модели CNN~\cite{yolo-review}.

В алгоритме YOLO входное изображение разбивается на фиксированное число сеток, а затем из каждой сетки предсказывается фиксированное число местоположений обрамляющих окон (bounding boxes) и вероятностей. Затем используется пороговое значение для выбора и определения местоположения объекта на изображении~\cite{yolo-review}.

Основной проблемой YOLO является более низкая точность при распознавании больших и малых объектов, а так же присущая всем одноэтапным алгоритмам потеря точности распознавания в сравнении с двухэтапными алгоритмами~\cite{yolo-review}.

Данное семейство алгоритмов включает в себя множество оптимизаций оригинального YOLO, среди которых:

\begin{itemize}
    \item[---] YOLOv2 (YOLO9000)~\cite{yolo9000};
    \item[---] YOLOv3~\cite{yolov3};
    \item[---] YOLOv3 tiny~\cite{yolov3-tiny}.
\end{itemize}

Последующие варианты алгоритма имеют малозначительные изменения, призванные улучшить его в конкретных задачах~\cite{yolov3-ships}. Последней опубликованной версией является YOLOv7~\cite{yolov7}.

\subsubsection*{SSD}

Алгоритм SSD (Single Shot MultiBox Detector) является альтернативным взгялдом на YOLO -- от последнего взяты наиболее удачные, с точки зрения авторов, решения, а так же привнесены свои идеи для повышения mAP и снижэения времени работы алгоритма~\cite{ssd}.

Отличительной особенностью является распознавание объектов за один прогон с помощью заданной сетки окон (default box) на пирамиде изображений, закодированой в сверточных тензорах. Таким образом алгоритм распознает как большие, так и маленькие объекты за один прогон сети~\cite{ssd}.

Второй версией алгоритма является MobileSSD, который является комбинацией двух нейросетевых алгоритмов -- MobileSSD и SSD~\cite{mobile-ssd}.

% В модификации YOLOv2 (так же известной как YOLO9000) точность распознавания достигает точности Faster R-CNN.
% Название YOLO9000 появилось из-за возможности распознавать порядка 9000 классов объектов на изображении и все еще обеспечивать обработку в реальном времени.

% В следующей модификации алгоритма, YOLOv3, еще больше повысилась точность распознавания объектов в сравнении с предыдущими версиями, а так же сниженное время обработки изображения за счет использования CNN Darknet-53 вместо Darknet-19.

% Так же была разработана модификация YOLOv3 tiny, имеющая меньшее количество слоев, что позволяет снизить требования алгоритма к аппаратному обеспечению (в частности - памяти).

% \section{Fast R-CNN}

% У R-CNN есть некоторые серьезные проблемы, такие как время, необходимое для извлечения RoI из-за использования процедуры selective search, многоступенчатость процесса и т.д.

% Для решения этих проблем в Fast R-CNN используется слой свертки перед извлечением RoI. Этот метод существенно сокращает количество RoI, в результате чего Fast R-CNN становится более эффективным, чем R-CNN. В Fast R-CNN обе задачи, идентификация каждого объекта вместе с их правильным расположением, были выполнены в одноэтапном процессе с помощью двух параллельных ветвей в выходном слое. Fast R-CNN использует слой объединения RoI для преобразования RoI переменной длины в выходные данные фиксированного размера перед подачей их на полносвязаные слои.

% \section{Faster R-CNN}

% Faster R-CNN является логическим продолжением алгоритма Fast R-CNN, но здесь авторы заменили процедуру selective search на сеть предложений регионов (RPN). RPN -- это CNN, используемая для создания высококачественных RoI. Faster R-CNN (объединяющая RPN и Fast R-CNN) может быть обучена сквозным образом. За счет использования RPN, в Faster R-CNN снижено время обнаружения объектов внутри входного изображения.

% Отдельно стоит отметить, что в зависимости от реализации RPN, изменяется точность распознавания определенных групп объектов. Пример влияния различных RPN на работу Faster R-CNN приведен в таблице~\ref{tbl:backbone-cmp}. Сравнение проводилось посредством бенчмарка COCO~\cite{coco-benchmark} в~\cite{yolov3}

%     \begin{table}[!h]
%         \small
%         \begin{center}
%             \caption{Сравнение существующих методов распознавания объектов}
%             \label{tbl:backbone-cmp}
%             \begin{tabular}{|l|l|ccc|ccc|}
%                 \hline
%                 & Алгоритм выделения & \multicolumn{3}{c|}{$AP_{IoU}$} & \multicolumn{3}{c|}{$AP_{object~size}$} \\
%                 & свойств объектов & $AP$ & $AP_{50}$ & $AP_{75}$ & $AP_S$ & $AP_M$ & $AP_L$ \\\hline

%                 \textit{Двухэтапные} & & & & & & & \\
%                 Faster R-CNN+++         & ResNet-101-C4           & 34.9 & 55.7 & 37.4 & 15.6 & 38.7 & 50.9 \\
%                 Faster R-CNN w FPN      & ResNet-101-FPN          & 36.2 & 59.1 & 39.0 & 18.2 & 39.0 & 48.2 \\
%                 Faster R-CNN by G-RMI   & Inception-ResNet-v2     & 34.7 & 55.5 & 36.7 & 13.5 & 38.1 & 52.0 \\
%                 Faster R-CNN w TDM      & Inception-ResNet-v2-TDM & 36.8 & 57.7 & 39.2 & 16.2 & 39.8 & 52.1 \\\hline
%                 \textit{Одноэтапные} & & & & & & & \\
%                 YOLOv2                  & DarkNet-19              & 21.6 & 44.0 & 19.2 & 5.0 & 22.4 & 35.5 \\
%                 SSD513                  & ResNet-101-SSD          & 31.2 & 50.4 & 33.3 & 10.2 & 34.5 & 49.8 \\
%                 DSSD513                 & ResNet-101-DSSD         & 33.2 & 53.3 & 35.2 & 13.0 & 35.4 & 51.1 \\
%                 RetinaNet               & ResNet-101-FPN          & 39.1 & 59.1 & 42.3 & 21.8 & 42.7 & 50.2 \\
%                 RetinaNet               & ResNeXt-101-FPN         & 40.8 & 61.1 & 44.1 & 24.1 & 44.2 & 51.2 \\
%                 YOLOv3 $608 \times 608$ & Darknet-53              & 33.0 & 57.9 & 34.4 & 18.3 & 35.4 & 41.9 \\
%                 \hline
%             \end{tabular}
%         \end{center}
%     \end{table}

\subsection{Параметры для сравнения}

Для оценки работы нейронной сети используется величина AP (Average Precision), вычисляемую по следующей формуле:

\begin{equation}
	AP = \frac{\text{кол-во верно распознанных объектов}}{\text{общее кол-во распознанных объектов}}.
\end{equation}

Однако, AP вычисляется для объектов одного класса, в связи с чем для классификаторов с несколькими возможными классами объектов используется величина mAP (англ. mean AP) -- среднее значение AP.

Кроме того, данную величину можно оценивать в зависимости от IoU (Intersection over Union), вычисляемую по формуле:

\begin{equation}
	IoU = \frac{\text{площадь пересечения областей}}{\text{площадь объединения областей}}.
\end{equation}

IoU описывает то, насколько предсказанные CNN обрамляющие окна близки к <<истинным>>. Данная величина принимает значения в диапазоне $[0;1]$, соответственно.

\subsection{Сравнение}

В таблицах~\ref{tbl:cmp-by-ap}~и~\ref{tbl:cmp-by-fps} приведены результаты сравнения работы рассмотренных выше нейросетевых алгоритов~\cite{yolov3}. 

Результаты, приведенные в таблице~\ref{tbl:cmp-by-ap}, получены посредством бенчмарка COCO~\cite{coco-benchmark} в~\cite{yolov3}.

\begin{table}[!h]
    \small
    \begin{center}
        \caption{Сравнение существующих методов распознавания объектов}
        \label{tbl:cmp-by-ap}
        \begin{tabular}{|l|ccc|ccc|}
            \hline
            & \multicolumn{3}{c|}{$AP_{IoU}$} & \multicolumn{3}{c|}{$AP_{object~size}$} \\
            & $AP$ & $AP_{50}$ & $AP_{75}$ & $AP_S$ & $AP_M$ & $AP_L$ \\\hline

            \textit{Двухэтапные} & & & & & & \\
            Faster R-CNN+++         & 34.9 & 55.7 & 37.4 & 15.6 & 38.7 & 50.9 \\
            Faster R-CNN w FPN      & 36.2 & 59.1 & 39.0 & 18.2 & 39.0 & 48.2 \\
            Faster R-CNN by G-RMI   & 34.7 & 55.5 & 36.7 & 13.5 & 38.1 & 52.0 \\
            Faster R-CNN w TDM      & 36.8 & 57.7 & 39.2 & 16.2 & 39.8 & 52.1 \\\hline
            \textit{Одноэтапные} & & & & & & \\
            YOLOv2                  & 21.6 & 44.0 & 19.2 & 5.0 & 22.4 & 35.5 \\
            SSD513                  & 31.2 & 50.4 & 33.3 & 10.2 & 34.5 & 49.8 \\
            DSSD513                 & 33.2 & 53.3 & 35.2 & 13.0 & 35.4 & 51.1 \\
            YOLOv3 $608 \times 608$ & 33.0 & 57.9 & 34.4 & 18.3 & 35.4 & 41.9 \\
            \hline
        \end{tabular}
    \end{center}
\end{table}

В таблице~\ref{tbl:cmp-by-fps} приведен результат сравнение проводившегося на основе набора данных \texttt{PASCAL VOC}~\texttt{2007}~и~\texttt{2012}~\cite{pascal-voc-dataset}, проученный в~\cite{yolov3}~и~\cite{ssd}.

\begin{table}[!h]
    \small
    \begin{center}
        \caption{Сравнение существующих методов}
        \label{tbl:cmp-by-fps}
        \begin{tabular}{|l|c|c|c|c|c|}
            \hline
            & \multicolumn{5}{c|}{\bfseries Критерии сравнения} \\ \cline{2-6}
            \bfseries Метод & \bfseries mAP & \bfseries Кол-во & \bfseries Кол-во & \bfseries FPS & \bfseries Разрешение \\
            & & \bfseries слоев & \bfseries  параметров & &\\\hline
            \textit{Двухэтапные} & & & & &\\
            \textit{алгоритмы} & & & & &\\
            Fast R-CNN              & 70.0 & --  & --          & 0.5 & -- \\
            Faster R-CNN VGG-16     & 73.2 & --  & --          & 7 & -- \\
            Faster R-CNN ResNet     & 76.4 & --  & --          & 5 & -- \\
            \textit{Одноэтапные} & & & & & \\
            \textit{алгоритмы} & & & & & \\
            YOLO                    & 63.4 & --  & --          & 45 & $448 \times 448$ \\
            SSD300                  & 74.3 & --  & --          & 46 & $300 \times 300$ \\
            SSD512                  & 76.8 & --  & --          & 19 & $512 \times 512$ \\
%            YOLOv2 $288 \times 288$ & 69.0 & 65  & 6.70452e+07 & 91 & $288 \times 288$ \\
%            YOLOv2 $352 \times 352$ & 73.7 & 65  & 6.70452e+07 & 81 & $352 \times 352$ \\
            YOLOv2 $416 \times 416$ & 76.8 & 65  & 6.70452e+07 & 67 & $416 \times 416$ \\
%            YOLOv2 $480 \times 480$ & 77.8 & 65  & 6.70452e+07 & 59 & $480 \times 480$ \\
%            YOLOv2 $544 \times 544$ & 78.6 & 65  & 6.70452e+07 & 40 & $544 \times 544$ \\
            YOLOv3                  & 79.2 & 222 & 6.15507e+07 & 70 & $416 \times 416$ \\
            YOLOv3 tiny             & 61.4 & 37  & 8.67824e+06 & 188 & $416 \times 416$ \\\hline
        \end{tabular}
    \end{center}
\end{table}

\section*{Вывод}

\subsection*{Скрытые Марковские модели}

Данный метод позволяет классифицировать объекты на изображении, основываясь на заранее заданном моделируемом процессе, используя для этого последовательности изображений. 

Необходимость в явном задании процесса и предобработке изображений с целью выделения признаков -- основные проблемы данного метода. При этом, размерность пространства признаков можно уменьшить используя определенные преобразования.

Один из способов упрощения моделируемого процесса -- использование CNN в качестве блока предобработки изображений, что позволит избавиться от необходимости явной разработки процесса.

\subsection*{Метод k-ближайших соседей}

Данный метод является простейшим классификатором, позволяющим классифицировать объект на изображении согласно заранее заданному множеству классов.

Основные проблемы метода:
\begin{itemize}
    \item[---] необходимость в явном задании $n$-мерного пространства признаков;
    \item[---] необходимость в явном задании функции расстояния в $n$-мерном пространстве признаков;
    \item[---] эмпирический подход к нахождению значения $K$;
    \item[---] ошибки классификации <<выбивающихся>> из класса объектов;
    \item[---] линейная зависимость времени работы от количества объектов в худшем случае;
    \item[---] линейная зависимость объема оперативной памяти, необходимой в процессе работы, от количества объектов.
\end{itemize}

Тем не менее, для относительно малого числа признаков и объектов, при условии изолированных классов, данный метод может быть использован в виду относительной простоты реализации.

\subsection*{Нейросетевые алгоритмы}

Нейросетевые алгоритмы выделяются на фоне альтернативных методов своей спобностью к самостоятельному выделению признаков на основе обучающей выборки и самостоятельному выделению кластеров объектов на основе полученных признаков.

Кроме того, при распознавании объектов на изображении нейросетевые алгоритмы нуждаются в минимальной предобработке, заключающейся в афинных преобразованиях входного изображения.

К преимуществам двух- и одноэтапных CNN относятся:
\begin{itemize}
    \item[---] способность к фильтрации шумов на входном изображении;
    \item[---] малое число настраиваемых весов в сравнении с полносвязными ANN;
    \item[---] константное время работы и объем оперативной памяти для конкретной CNN.
\end{itemize}

При этом современные одноэтапные алгоритмы практически не уступают двухэтапным с точки зрения точности распознавания (для YOLOv3 mAP=79.2, для Faster R-CNN -- 76.4), существенно превосходя их с точки зрения времени работы (YOLOv3 tiny FPS = 188, Faster R-CNN -- 5). Это позволяет использовать одноэтапные CNN в задачах распознавания в реальном времени.

Тем не менее, у CNN слишком большое число варьируемых параметров: количество слоёв, размерность ядра свёртки для каждого из слоёв, количество ядер для каждого из слоёв, шаг сдвига ядра при обработке слоя и т.д. 

Параметры сети существенно влияют на результаты работы, однако в настоящее время выбираются эмпирически. Существует несколько выверенных и отлаженных CNN, но отсутствуют рекомендации, согласно которым нужно проектировать нейросетевой алгоритм для новой задачи.

Так же, недостатком CNN, как и остальных нейросетевых алгоритмов является варьирование результатов обучения, связанная с самой структурой алгоритмов.