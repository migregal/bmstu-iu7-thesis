\chapter{Конструкторский раздел}

\section{Требования}

\subsection*{К разрабатываемому методу}

Метод распознавания надводных объектов должен:
\begin{itemize}[label=---]
    \item принимать на вход изображения в форматах PNG, JPG, JPEG, BMP с размером от $640 \times 640$ до $1280 \times 1280$ включительно;
    \item производить распознавание различимых надводных объектов в дневное время суток.
\end{itemize}

\subsection*{К разрабатываемому программному комплексу}

Программный комплекс, реализующий интерфейс для разработанного метода, должен предоставлять:
\begin{itemize}[label=---]
    \item возможность загрузки изображений через графический интерфейс;
    \item возможность создания итогового изображения с обрамляющими окнами обнаруженных объектов.
\end{itemize}

\section{Выбор семейства/метода обнаружения}

На основании данных из таблицы~\ref{tbl:cmp-by-ap}, в качестве метода обнаружения выбрана CNN YOLOv8n.

Данный выбор обусловлен более высокой точностью метода в сравнении с YOLOv5n. Кроме того, YOLOv8n обладает более низкими требованиями как к размеру обучающей выборки, так и к аппаратному обеспечению в сравнении как с YOLOv5x, так и с YOLOv8x.

В дополнение к выше сказанному, стоит отметить, что все масштабные версии YOLOv8 представлены в виде общедоступных пакетов для языка программирования Python~3~\cite{python3}, что существенно упрощает использование данного метода.

\section{Проектирование метода распознавания}

На рисунках~\ref{img:method-a1}~и~\ref{img:method-a2} представлена IDEF0 диаграмма метода уровня A1, а так же ветки A2.

\includeimage{method-a1}{f}{h}{0.9\textwidth}{IDEF0-диаграмма. Уровень A1}

\includeimage{method-a2}{f}{h}{0.8\textwidth}{IDEF0-диаграмма. Ветка A2}

\section{Объединение результатов работы слабых экспертов}

Результатом работы слабых экспертов является множество обрамляющих окон, а так же соответствующие меры достоверности результатов.

В общем случае, обрамляющие окна, полученные в результате работы слабых экспертов могут пересекаться или же полностью дублироваться. Кроме того, в разрабатываемом методе предполагается учитывание весовых коэффициентов соответствующих слабых экспертов для корректировки результатов работы в случае, когда контекст снимка заранее известен.

\clearpage

Соответствующая схема алгоритма представлена на рисунке~\ref{img:deduplicate_wbboxes}.

\includeimage{deduplicate_wbboxes}{f}{h}{0.85\textwidth}{Схема алгоритма объединения результатов работы слабых экспертов}

Для того, чтобы обнаружить пересечение обрамляющих окон, необходимо установить порог значения IoU, при превышении которого окна считаются пересекающимися. Такое решение обусловлено контекстом решаемой задачи --- при съемке с большого расстояния нгадводные объекты могут частично накладываться, что должно быть учтено в разрабатываемом методе.

Схема алгоритма обнаружения пересечений обрамляющих окон представлена на рисунке~\ref{img:intersection_matrix}

\includeimage{intersection_matrix}{f}{h}{0.85\textwidth}{Схема алгоритма обнаружения пересечений обрамляющих окон}

В процессе обработки результатов работы слабых экспертов возможна ситуация, при которой пересекающиеся окна имеют одинаковый вес и, соответственно, становится невозможным выбор лишь одного из окон. 

В качестве алгоритма разрешения подобных конфликтов предолагается использовать выбор наиболее близкого к центру масс пересечения какого-либо из подмножеств пересекающихся окон. При этом под наиболее близки понимаеется окно с наименьшим Евклидовым расстоянием между центром окна и центром масс, соотвественно.

Соответствующая схема алгоритма представлена на рисунке~\ref{img:intersection}

\includeimage{intersection}{f}{h}{0.8\textwidth}{Схема алгоритма пересечения обрамляющих окон}


\section{Структура разрабатываемого программного комплекса}

Разрабатываемый программный комплекс состоит из двух модулей:
\begin{itemize}[label=---]
    \item модуль, реализующий модель YOLOv8 сети для распознавания объектов;
    \item пользовательское приложение, производящее распознавание объектов на основе полученной модели.
\end{itemize}

\subsection*{Модуль YOLOv8 модели}

В данном модуле происходит только обучение и сохранение модели. Модуль должен быть использован либо при первоначальном обучении модели, либо при последующем дообучении в связи с вносящимися изменениями.

Результатом работы модуля является файл, содержит в себе обученную модель, т.е. ее структуру и весовые коэффициенты соответствующих связей. Это необходимо для того, чтобы не тратить время на обучение модели при повторном использовании, так как процесс обучения может занимать продолжительный период времени в зависисмотси от некоторых факторов.

На рисунке~\ref{img:module-yolov8} представлена схема работы с модулем YOLOv8 модели.

\includeimage{module-yolov8}{f}{h}{\textwidth}{Схема работы с модулем YOLOv8 модели}


\subsection*{Модуль пользовательского приложения}

Данный модуль позволяет пользователю загружать изображение для последующего анализа и выбора параметров настройки метода (весовых коэффициентов слабых экспертов). Результатом работы модуля является изображение с выделенными надводными объектами.

На рисунке~\ref{img:module-user} представлена схема работы с модулем пользовательского приложения.

\includeimage{module-user}{f}{h}{\textwidth}{Схема работы с модулем пользовательского приложения}

\section{Данные для обучения модели}

В качестве данных для обучения моделей были выбраны три общедоступных набора данных: Kaggle~Ships~in~Google~Earth~\cite{kaggle-ships-in-google-earth-dfqwt_dataset}, ShipRSImageNet~\cite{shiprs-imagenet} и Huawei~Ship~\cite{huawei_ship_dataset}.

Далее приводится описание каждого из использованных наборов данных.

\subsection*{Kaggle Ships In Google Earth}

Данный набор данных содержит 1658 снимков, содержащих более двух тысяч надводных объектов в различных контекстах (например, в портовой зоне и в открытом море).

В виду малого числа изображений, набор даных будет разделятся в следующих пропорциях: 85:5:10 для обучающей, тестовой и валидационной частей, соответственно.

На рисунках~\ref{img:GE_17_jpg.rf.feb86f8f13e200e62e849939c5ea5c7a}~и~\ref{img:GE_688_jpg.rf.b9a18e0b7a5109a8c946465a475f893f} представлены примеры снимков из набора данных.

\includeimage{GE_17_jpg.rf.feb86f8f13e200e62e849939c5ea5c7a}{f}{h}{0.3\textwidth}{Пример снимка из датасета (портовая зона)}

\includeimage{GE_688_jpg.rf.b9a18e0b7a5109a8c946465a475f893f}{f}{h}{0.3\textwidth}{Пример снимка из датасета (открытое море)}

\subsection*{ShipRSImageNet}

В связи с относительно малым числом снимков в описанном выше наборе данных, в дополнение к последнему, будет использован еще один, специально собранный для обучения нейронных сетей в задачах расс познавания.

ShipRSImageNet состоит из 3435 снимков, содержащих в общей сложности более 17.5~тысяч объектов, размеченных как с использованием как горизонтальных, так и ориентированнызх обрамляющих окон. 

Кроме того, экспертами была проведена разметка объектов по их принадлежности к одному из 50 классов кораблей и судов, что может быть использовано в будущем в рамках одного из направлений развития разрабатываемого метода.

Примеры снимков из этого набора данных приведены на рисунках~\ref{img:1448__0_0}~и~\ref{img:2000000014}.

\includeimage{1448__0_0}{f}{h}{0.3\textwidth}{Пример снимка из датасета (портовая зона)}

\includeimage{2000000014}{f}{h}{0.3\textwidth}{Пример снимка из датасета (открытое море)}

\subsection*{Huawei Ship}

Состоит из 5538 снимков различных надводных объектов (преимущественно судов и кораблей) с различных ракурсов и расстояний, а так же в разных погодных условиях. В общей сложности набор содержит 8132 размеченных надводных объекта, относящихся к одному из восьми представленных классов. 

В связи с особенностями работы сверточных нейронных сетей, данный набор данных необъодимо обогатить, чтобы повысить точность работы метода обнаружения. Данная необходимость вызвана большим числом обрабатываемых признаков объектов, в сравнении с предыдущими наборами данных.

Примеры снимков из этого набора данных приведены на рисунках~\ref{img:583_jpg.rf.3bc7cd6c979fe0c7c28e334b01187fe5},~\ref{img:2795_jpg.rf.1cb16e7aceb997ff1f3f73ae137de99c}~и~\ref{img:2678_jpg.rf.3f232625601f1833d1e6b0a73b887c75}.

\includeimage{583_jpg.rf.3bc7cd6c979fe0c7c28e334b01187fe5}{f}{h}{0.3\textwidth}{Пример снимка из датасета (корабль)}

\includeimage{2795_jpg.rf.1cb16e7aceb997ff1f3f73ae137de99c}{f}{h}{0.3\textwidth}{Пример снимка из датасета (судно в тумане)}

\includeimage{2678_jpg.rf.3f232625601f1833d1e6b0a73b887c75}{f}{h}{0.3\textwidth}{Пример снимка из датасета (буй)}

\section{Обогащение данных}

В связи с малым числом изображений в обучающей выборке Huawei~Ship, для каждого из представленных снимков по отдельности применены следующие трансформации (с различными параметрами):
\begin{itemize}[label=---]
    \item горизонтальное отражение;
    \item поворот (до 15 градусов);
    \item усредняющее размытие;
    \item Гауссово размытие;
    \item выравнивание гистограммы;
    \item исключение (до 20\%);
    \item Гауссов шум;
    \item повышение цветового тона;
    \item изменение резкости.
\end{itemize}

\section{Формат хранения разметки данных}

Формат хранения данных обусловлен соглашением о формате в семействе YOLO. Данные описываются YAML--файлом, содержащим всю информацию о выборке. Пример приведен в листинге~\ref{lst:data.yaml} 

\includelisting{data.yaml}{Описание выборки в формате YOLO}

В данном примере описываются три подвыборки (тренировочная, тестовая и валидационная), а так же классы объектов, представленных в выборке, использующиеся при решении задачи классификации объектов: общее число классов, а так же соответствующие названия, используемые при разметке обработанных изображений.
 
Каждая подвыборка содержит две поддиректории: изображения и аннотации в формате YOLO. Пример аннотации представлен в листинге~\ref{lst:label.txt}.

\includelisting{label.txt}{Пример аннотации в формате YOLO}

В данном формате аннотации содержат следующую информацию: порядковый номер класса объекта, нормализованные координаты левого верхнего угла обрамляющего окна, нормализованные ширину и высоту обрамляющего окна. Такой формат позволяет работать с изображениями даже при масштабировании последних.

\section{Обучение и тестирование слабых экспертов}

Так как в данной методе используется бэггинг, то каждый из слабых экспертов будет обучаться независимо от остальных. В связи с этим, выборка должна быть разделена на $n$ непересекающихся выборок, где $n$ --- число слабых экспертов.

В общем случае для обучения и тестирования слабых экспертов полученные после разделения выборки примерно разделяются в соотношении $80:15:5$ на обучающую, тестовую и валидационную подвыборки, соответственно.

С учетом приведенного выше описания наборов данных, в методе распознавания будет использовано 3 слабых эксперта, обучаемых на соответствующем наборе данных. Тестирование каждого из обученных слабых экспертов будет производится на основании данных, представленных в соотвтествующем наборе данных, в связи со спецификой каждого и последних.

\section{Вывод}