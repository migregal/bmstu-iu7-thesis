\chapter{Основная часть}

\section{Формальная постановка задачи}

Входными данными метода является изображение. Результатом работы являются объекты распознавания, а именно --- список обрамляющих окон, соответстующих распозныннам объектам.

На рисунке~\ref{img:method} представлена диаграмма, описывающая общий вид метода распознавания надводных объектов с использованием нейронных сетей.

\includeimage{method}{f}{h}{0.8\textwidth}{Общий вид метода}

На метод накладываются следующие ограничения:
\begin{itemize}[label=---]
    \item входные данные --- фотоснимок в формате PNG, JPG, JPEG;
    \item размерность входного изображения --- не ниже $640 \times 640$ и не более $1280 \times 1280$ пикселей;
    \item разрешение входного изображения --- от 0.5 до 15 метров/пиксель;
    \item работа только в дневное время суток (так как метод, разработанный для <<ночной>> работы может обладать совершенно другими свойствами);
    \item распознавание только различимых объектов на изображении.
\end{itemize}

На рисунке~\ref{img:method-a1} представлена IDEF0 диаграмма метода уровня A1.

\includeimage{method-a1}{f}{h}{0.9\textwidth}{IDEF0-диаграмма. Уровень A1}

\section{Бэггинг}

В бэггинге все слабые эксперты обучаются и работают параллельно, т.~е. независимо друг от друга. При этом обучающая выборка $X$ разделяется на $n$ выборок $X_1, X_2, \dots, X_n$, причем $X_i$ и $X_j$ могут пересекаться при любых $i,j \in 1 \dots n$.

Идея данного подхода заключается в том, что в отличие от бустинга классификаторы не исправляют ошибки друг друга, а компенсируют их при голосовании~\cite{ensembles}. 

При этом в данной работе результат голосования определяется посредством взвешивания --- каждому классификатору присваивается вес, учитываемый при принятии решения.

Схема бэггинга представлена на рис.~\ref{img:bagging}.

\includeimage{bagging}{f}{h}{\textwidth}{Схематическое представление алгоритма бэггинга}

Преимуществом данного метода перед стекингом является детерминированность результата: мета-модель в стекинге может переобучаться с течением времени, в то время как результат голосования в беггинге является детерминированным~\cite{ensembles}.

\section{Объединение результатов работы слабых экспертов}

Результатом работы слабых экспертов является множество обрамляющих окон, а так же соответствующие меры достоверности результатов.

В общем случае, обрамляющие окна, полученные в результате работы слабых экспертов могут пересекаться или же полностью дублироваться. Кроме того, в разрабатываемом методе предполагается учитывание весовых коэффициентов соответствующих слабых экспертов для корректировки результатов работы в случае, когда контекст снимка заранее известен.

Соответствующая схема алгоритма представлена на рисунке~\ref{img:deduplicate_wbboxes}.

Для того, чтобы обнаружить пересечение обрамляющих окон, необходимо установить порог значения IoU, при превышении которого окна считаются пересекающимися. Такое решение обусловлено контекстом решаемой задачи --- при съемке с большого расстояния нгадводные объекты могут частично накладываться, что должно быть учтено в разрабатываемом методе.

Схема алгоритма обнаружения пересечений обрамляющих окон представлена на рисунке~\ref{img:intersection_matrix}

В процессе обработки результатов работы слабых экспертов возможна ситуация, при которой пересекающиеся окна имеют одинаковый вес и, соответственно, становится невозможным выбор лишь одного из окон. 

В качестве алгоритма разрешения подобных конфликтов предолагается использовать выбор наиболее близкого к центру масс пересечения какого-либо из подмножеств пересекающихся окон. При этом под наиболее близким понимаеется окно с наименьшим Евклидовым расстоянием между центром окна и центром масс, соотвественно.

Соответствующая схема алгоритма представлена на рисунке~\ref{img:intersection}

\section{Структура разрабатываемого программного комплекса}

Разрабатываемый программный комплекс состоит из двух модулей:
\begin{itemize}[label=---]
    \item модуль, реализующий метод распознавания объектов с использованием модели YOLOv8;
    \item пользовательское приложение, производящее распознавание объектов на основе разработанного метода, а так же предоставляющее возможность обучения модели, используемой в предыдущем модуле.
\end{itemize}

\subsection*{Модуль YOLOv8 модели}

В данном модуле происходит только обучение и сохранение модели. Модуль должен быть использован либо при первоначальном обучении модели, либо при последующем дообучении в связи с вносящимися изменениями.

Результатом работы модуля является файл, содержит в себе обученную модель, т.е. ее структуру и весовые коэффициенты соответствующих связей. Это необходимо для того, чтобы не тратить время на обучение модели при повторном использовании, так как процесс обучения может занимать продолжительный период времени в зависисмотси от некоторых факторов.

На рисунке~\ref{img:module-yolov8} представлена схема работы с модулем YOLOv8 модели.

\includeimage{module-yolov8}{f}{h}{\textwidth}{Схема работы с модулем YOLOv8 модели}


\subsection*{Модуль пользовательского приложения}

Данный модуль позволяет пользователю загружать изображение для последующего анализа и выбора параметров настройки метода (весовых коэффициентов слабых экспертов). Результатом работы модуля является изображение с выделенными надводными объектами.

На рисунке~\ref{img:module-user} представлена схема работы с модулем пользовательского приложения.

\includeimage{module-user}{f}{h}{\textwidth}{Схема работы с модулем пользовательского приложения}


\section{Данные для обучения модели}

В качестве данных для обучения моделей были выбраны три общедоступных набора данных: Kaggle~Ships~in~Google~Earth~\cite{kaggle-ships-in-google-earth-dfqwt_dataset}, ShipRSImageNet~\cite{shiprs-imagenet} и Huawei~Ship~\cite{huawei_ship_dataset}.

В таблице~\ref{tbl:cmp-by-ap} приводится общая информация о каждом из используемых наборов данных.

\begin{table}[!h]
    \small
    \begin{center}
        \caption{Сравнение наборов данных}
        \label{tbl:cmp-by-ap}
        \begin{tabular}{|l|cc|c|}
            \hline
            Набор  & \multicolumn{2}{c|}{Число} & Ракурс \\\cline{2-3}
            данных & снимков, шт. & объектов, шт. & \\\hline

            Kaggle~Ships & 1658 & > 2000  & Спутник \\    
            ShipRSImageNet & 3435 & > 17500 & Спутник \\
            Huawei~Ship & 5538 & 8132 & БПЛА \\
            \hline
        \end{tabular}
    \end{center}
\end{table}

\section{Обогащение данных}

В связи с малым числом изображений в обучающей выборке Huawei~Ship, для каждого из представленных снимков по отдельности применены были применены трансформации (с различными параметрами): горизонтальное отражение, поворот (до 15 градусов), различные алгоритмы размытия, выравнивание гистограммы, исключение (до 20\%), наложение Гауссова шума, изменение цветового тона и резкости.

\section{Обучение и тестирование слабых экспертов}

Так как в данной методе используется бэггинг, то каждый из слабых экспертов будет обучаться независимо от остальных. В связи с этим, выборка должна быть разделена на $n$ непересекающихся выборок, где $n$ --- число слабых экспертов.

В общем случае для обучения и тестирования слабых экспертов полученные после разделения выборки примерно разделяются в соотношении $80:15:5$ на обучающую, тестовую и валидационную подвыборки, соответственно.

С учетом приведенного выше описания наборов данных, в методе распознавания будет использовано 3 слабых эксперта, обучаемых на соответствующем наборе данных. Тестирование каждого из обученных слабых экспертов будет производится на основании данных, представленных в соотвтествующем наборе данных, в связи со спецификой каждого из последних.

\section{Средства реализации}

\subsection*{Выбор языка программирования}

Для реализации программного комплекса будет использоваться язык программирования Python~3~\cite{python3}. Данный выбор обусловлен следующими факторами:
\begin{itemize}[label=---]
    \item широкий набор библиотек для работы с нейронными сетями;
    \item возможность обучать нейронную сеть на графическом процессоре с
использованием технологии CUDA~\cite{cuda}.
\end{itemize}

Кроме того, как указывалось ранее, для выбранного языка программирования уже существуют общедоступные пакеты для работы с выбранным методом обнаружения, включая методы для обучения, тестирования и валидации работы метода.

\subsection*{Выбор библиотеки глубокого обучения}

Для создания и обучения модели нейронной сети была выбрана библиотека PyTorch~\cite{pytorch} версии 2.0.0. Выбор данной версии обусловлен поддержкой CUDA 11.8, предоставляемой GPU NVIDIA GeForce RTX 2060~\cite{rtx2060}, на котором будет производиться обучение нейронной сети.

\section{Реализация программного комплекса}

\subsection{Модуль метода распознавания}

Реализация модуля построена на YOLOv8n модели. Модуль состоит из трех слабых экспертов, обученных с использованием различных наборов данных, как было описано ранее.

В связи с тем, что данные слабые эксперты не зависят от результатов работы друг друга, присутствует возможность распараллеливания процесса обработки изображения слабыми экспертами с целью снижения времени отклика системы.

Для организации параллельной обработки будет использован Ray --- фреймворк с открытым исходным кодом, предоставляющий возможность параллельного выполнения, а так же кластеризации различного рода вычислений, в том числе при использовании нейронных сетей~\cite{pkg-ray}. 

\subsection{Обучение слабых экспертов}

В предоставляемом Ultralytics пакете для работы с YOLOv8 предусмотрены методы для обучения моделей с различными параметрами и возможностью применения таких оптимизаций, как батчинг изображений, мозаичная аугментация на ранних стадиях обучения, отслеживание результатов процесса обучения с прерыванием в случае простоя и прочие~\cite{pkg-ultralytics}.

Помимо этого, указанный выше пакет предоставляет средства для автоматической предобработки изображения (его масштабирования) при превышении размера, использованного при обучении модели. В совокупности с использованием нормализованных координат при формаировании результатов распознавания, это позволяет полностью переложить процесс предобработки на описанный выше пакет.

\section{Результаты обучения слабых экспертов}

В таблице~\ref{tbl:cmp-by-precision} приведена общая информаци по итогам обучения слабых экспертов в зависимотси от набора данных.

\begin{table}[!h]
    \small
    \begin{center}
        \caption{Сравнение результатов обучения на наборах данных}
        \label{tbl:cmp-by-precision}
        \begin{tabular}{|l|c|cc|c|}
            \hline
            Набор  & Всего & \multicolumn{2}{c|}{Порог} & Достигнутая\\\cline{3-4}
            данных & эпох, шт. & эпоха, шт. & точность, \%. & точность, \% \\\hline

            Kaggle~Ships & 100 & 30 & 80 & 92 \\    
            ShipRSImageNet & 100 & 40 & 60 & 85 \\
            Huawei~Ship    & 15 & --- & --- & 83 \\
            \hline
        \end{tabular}
    \end{center}
\end{table}

На рисунке~\ref{plt:precision} приведена графическая интерпретация процесса обучения слабых экспертов.

\begin{figure}[htp]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			axis lines=left,
			xlabel={Эпоха},
			ylabel={P},
			legend pos=south east,
			ymajorgrids=true,
			xmajorgrids=true,
			xtick={10,20,30,40,50,60,70,80,90,100}
		]
			\addplot table[x=epoch,y=metrics/precision(B),col sep=comma] {inc/csv/train_1.csv};
			
            \addplot table[x=epoch,y=metrics/precision(B),col sep=comma] {inc/csv/train_3.csv};

			\addplot table[x=epoch,y=metrics/precision(B),col sep=comma] {inc/csv/train_2.csv};
			
            \legend{Kaggle~Ships, Huawei~Ship, ShipRSImageNet}
		\end{axis}
	\end{tikzpicture}
	\captionsetup{justification=centering}
	\caption{Точность слабых экспертов (P)}
	\label{plt:precision}
\end{figure}

Различия в кривых обучения между Kaggle~Ship и ShipRSImageNet объяснются отличиями в содержимом наборов данных, а так же различиями в точности разметки данных в различных наборах.

В процессе обучения с использованием Huawei~Ship, модель завершила обучение на 15ой эпохе. Данный факт был установлен экспериментально --- в течение 50-ти эпох после этого не было отмечено значительных изменений в точности обнаружения обхъектов.

\section{Примеры использования разработанного программного комплекса}

Модуль, реализующий метод распознавания объектов с использованием модели YOLOv8 выполнен в виде пакета на языке Python~3 и не предоставляет пользовательского интерфейса для работы с ним.

В то же время, модуль пользовательского приложения представляет собой  консольное приложение без графического интерфейса, конфигурируемые при помощи аргументов командной строки.

В листингах~\ref{lst:train_help.txt}~и~\ref{lst:cli_help.txt} приведены примеры взаимодействия с пользовательским модулем.

\includelisting{train_help.txt}{Взаимодействие с пользовательским приложением обучения модели}

\includelisting{cli_help.txt}{Взаимодействие с пользовательским приложением распознавания объектов}
